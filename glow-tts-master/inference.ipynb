{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\OneDrive\\Documents\\studie\\TextSpeech\\glow-tts-master\n",
      "in monotonic_alighn c:\\Users\\jacob\\OneDrive\\Documents\\studie\\TextSpeech\\glow-tts-master\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mattentions\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodules\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# load WaveGlow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacob\\OneDrive\\Documents\\studie\\TextSpeech\\glow-tts-master\\models.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcommons\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mattentions\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmonotonic_align\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDurationPredictor\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, filter_channels, kernel_size, p_dropout):\n",
      "File \u001b[1;32mc:\\Users\\jacob\\OneDrive\\Documents\\studie\\TextSpeech\\glow-tts-master\\monotonic_align\\__init__.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min monotonic_alighn\u001b[39m\u001b[38;5;124m'\u001b[39m , os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/monotonic_align\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m maximum_path_c\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmaximum_path\u001b[39m(value, mask):  \n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\" Cython optimised version.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m  value: [b, t_x, t_y]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m  mask: [b, t_x, t_y]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from text import text_to_sequence, cmudict\n",
    "from text.symbols import symbols\n",
    "import commons\n",
    "import attentions\n",
    "import modules\n",
    "\n",
    "import models\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "# load WaveGlow\n",
    "waveglow_path = './waveglow/waveglow_256channels_ljs_v3.pt' # or change to the latest version of the pretrained WaveGlow.\n",
    "waveglow = torch.load(waveglow_path)['model']\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "_ = waveglow.cuda().eval()\n",
    "from apex import amp\n",
    "waveglow, _ = amp.initialize(waveglow, [], opt_level=\"O3\") # Try if you want to boost up synthesis speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using your own trained model\n",
    "model_dir = \"./logs/your_dir/\"\n",
    "hps = utils.get_hparams_from_dir(model_dir)\n",
    "checkpoint_path = utils.latest_checkpoint_path(model_dir)\n",
    "\n",
    "# If you are using a provided pretrained model\n",
    "# hps = utils.get_hparams_from_file(\"./configs/any_config_file.json\")\n",
    "# checkpoint_path = \"/path/to/pretrained_model\"\n",
    "\n",
    "model = models.FlowGenerator(\n",
    "    len(symbols) + getattr(hps.data, \"add_blank\", False),\n",
    "    out_channels=hps.data.n_mel_channels,\n",
    "    **hps.model).to(\"cuda\")\n",
    "\n",
    "utils.load_checkpoint(checkpoint_path, model)\n",
    "model.decoder.store_inverse() # do not calcuate jacobians for fast decoding\n",
    "_ = model.eval()\n",
    "\n",
    "cmu_dict = cmudict.CMUDict(hps.data.cmudict_path)\n",
    "\n",
    "# normalizing & type casting\n",
    "def normalize_audio(x, max_wav_value=hps.data.max_wav_value):\n",
    "    return np.clip((x / np.abs(x).max()) * max_wav_value, -32768, 32767).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_stn = \"Glow TTS is really awesome !\" \n",
    "\n",
    "if getattr(hps.data, \"add_blank\", False):\n",
    "    text_norm = text_to_sequence(tst_stn.strip(), ['english_cleaners'], cmu_dict)\n",
    "    text_norm = commons.intersperse(text_norm, len(symbols))\n",
    "else: # If not using \"add_blank\" option during training, adding spaces at the beginning and the end of utterance improves quality\n",
    "    tst_stn = \" \" + tst_stn.strip() + \" \"\n",
    "    text_norm = text_to_sequence(tst_stn.strip(), ['english_cleaners'], cmu_dict)\n",
    "sequence = np.array(text_norm)[None, :]\n",
    "print(\"\".join([symbols[c] if c < len(symbols) else \"<BNK>\" for c in sequence[0]]))\n",
    "x_tst = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
    "x_tst_lengths = torch.tensor([x_tst.shape[1]]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  noise_scale = .667\n",
    "  length_scale = 1.0\n",
    "  (y_gen_tst, *_), *_, (attn_gen, *_) = model(x_tst, x_tst_lengths, gen=True, noise_scale=noise_scale, length_scale=length_scale)\n",
    "  try:\n",
    "    audio = waveglow.infer(y_gen_tst.half(), sigma=.666)\n",
    "  except:\n",
    "    audio = waveglow.infer(y_gen_tst, sigma=.666)\n",
    "ipd.Audio(normalize_audio(audio[0].clamp(-1,1).data.cpu().float().numpy()), rate=hps.data.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
