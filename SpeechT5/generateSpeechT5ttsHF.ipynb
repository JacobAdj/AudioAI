{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58146025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\bin\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model & processor loaded\n",
      "speaker embeddings & vocoder loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# from IPython.display import Audio\n",
    "\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "\n",
    "from datasets import load_dataset \n",
    "\n",
    "from transformers import SpeechT5ForTextToSpeech, SpeechT5Processor\n",
    "from transformers import SpeechT5HifiGan\n",
    "\n",
    "\n",
    "MODEL_NAME = \"microsoft/speecht5_tts\"\n",
    "\n",
    "CACHE_DIR = \"D:/LanguageModels/cache\"\n",
    "DATASET_DIR = \"D:/LanguageModels/dataset/\"\n",
    "AUDIO_DIR = \"D:/LanguageModels/dataset/audio/\"\n",
    "\n",
    "finetuned = False\n",
    "\n",
    "if finetuned:\n",
    "    model = SpeechT5ForTextToSpeech.from_pretrained(\"D:/LanguageModels/ftT5modelGetallen\")\n",
    "    processor = SpeechT5Processor.from_pretrained(\"D:/LanguageModels/ftT5processorGetallen\")\n",
    "else:\n",
    "    model = SpeechT5ForTextToSpeech.from_pretrained(MODEL_NAME , cache_dir=CACHE_DIR)\n",
    "    processor = SpeechT5Processor.from_pretrained(MODEL_NAME , cache_dir=CACHE_DIR)\n",
    "\n",
    "print('model & processor loaded')\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.requires_grad) \n",
    "\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\" , cache_dir=CACHE_DIR)\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\" , cache_dir=CACHE_DIR)\n",
    "\n",
    "print('speaker embeddings & vocoder loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c771b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"input_ids\"] tensor([[ 4,  9,  5, 21,  5,  9,  2]])\n",
      "spectrogram tensor([[-6.1812, -6.0740, -6.2466,  ..., -7.5092, -7.3178, -6.9933],\n",
      "        [-5.0527, -5.2447, -5.1299,  ..., -5.5963, -5.4195, -5.3859],\n",
      "        [-4.7476, -4.8096, -4.6938,  ..., -5.1124, -4.9849, -5.0775],\n",
      "        ...,\n",
      "        [-4.9865, -4.8153, -4.7756,  ..., -4.8943, -4.9383, -4.9652],\n",
      "        [-4.8076, -4.8270, -4.8703,  ..., -4.8362, -4.8711, -4.8943],\n",
      "        [-4.6025, -4.6175, -4.6118,  ..., -4.8453, -4.8828, -4.9767]])\n",
      "spectrogram type <class 'torch.Tensor'>\n",
      "speech tensor([ 7.7285e-06,  1.3608e-05, -1.9907e-06,  ..., -1.1225e-05,\n",
      "         1.1667e-05, -6.2211e-06])\n",
      "speech shape torch.Size([14848])\n",
      "Speech synthesis complete and saved for number negen to ./output/negen_T5modelFineGetallen.wav\n"
     ]
    }
   ],
   "source": [
    "getal = 'negen'\n",
    "\n",
    "inputs = processor(text = getal, return_tensors=\"pt\")\n",
    "\n",
    "print('inputs[\"input_ids\"]' , inputs[\"input_ids\"] )\n",
    "\n",
    "spectrogram = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings)\n",
    "\n",
    "print('spectrogram' , spectrogram)\n",
    "print('spectrogram type' , type(spectrogram))\n",
    "\n",
    "# # Convert PyTorch tensor to NumPy array\n",
    "# spectrogramnp = spectrogram.cpu().numpy().T\n",
    "\n",
    "# print('spectrogramnp.shape' , spectrogramnp.shape)\n",
    "\n",
    "# # Convert Mel spectrogram back to audio\n",
    "# speech = librosa.feature.inverse.mel_to_audio(spectrogramnp, sr=16000)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "print('speech' , speech)\n",
    "print('speech shape' , speech.shape)\n",
    "\n",
    "# Play the sound\n",
    "sd.play(speech, 16000)\n",
    "sd.wait()  # Wait until playback finishes\n",
    "\n",
    "outfilename = ''\n",
    "\n",
    "if finetuned:\n",
    "    outfilename = './output/' + getal + '_T5modelFineGetallen.wav'\n",
    "else:\n",
    "    outfilename = './output/' + getal + '_T5modelOrigGetallen.wav'\n",
    "\n",
    "sf.write(outfilename, speech, 16000)\n",
    "\n",
    "print(\"Speech synthesis complete and saved for number \" + getal + ' to ' + outfilename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
