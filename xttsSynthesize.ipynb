{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbe5bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config OK\n",
      "init OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\bin\\Python309\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model OK\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "import soundfile as sf\n",
    "\n",
    "# Load model configuration\n",
    "config = XttsConfig()\n",
    "config.load_json('./xtts/config.json')\n",
    "\n",
    "print('config OK')\n",
    "\n",
    "# Step 2: Initialize the model\n",
    "model = Xtts.init_from_config(config)\n",
    "\n",
    "print('init OK')\n",
    "\n",
    "# Step 3: Load the pre-trained weights\n",
    "model.load_checkpoint(config, checkpoint_dir=\"D:/LanguageModels/xtts/\", eval=True)\n",
    "\n",
    "print('model OK')\n",
    "\n",
    "# Optional: If you have CUDA installed and want to use GPU, uncomment the line below\n",
    "# model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab73f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer <TTS.tts.layers.xtts.tokenizer.VoiceBpeTokenizer object at 0x0000021383424FD0>\n",
      "['19', '2025']\n",
      "num 2\n",
      "het is vandaag negentien april tweeduizend vijfentwintig\n",
      "Speech synthesis complete and saved\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"EINOPS_BACKEND\"] = \"torch\"\n",
    "\n",
    "# import einops\n",
    "\n",
    "# model.tokenizer = VoiceBpeTokenizer(vocab_file=\"path/to/vocab.json\")\n",
    "\n",
    "import re\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "from expandnumbers import getal_in_woorden\n",
    "\n",
    "print('tokenizer' , model.tokenizer)\n",
    "\n",
    "\n",
    "sentence = \"het is vandaag 19 april 2025\"\n",
    "numbers = re.findall(r'\\d+', sentence)\n",
    "\n",
    "print(numbers)  # Output: ['19', '2025']\n",
    "\n",
    "# Replace numbers with words\n",
    "def replace_numbers(text):\n",
    "    return re.sub(r'\\d+', lambda x: getal_in_woorden(int(x.group())), text)\n",
    "# def replace_numbers(text):\n",
    "#     return re.sub(r'\\d+', lambda x: num2words(int(x.group()), lang='nl'), text)\n",
    "\n",
    "converted_sentence = replace_numbers(sentence)\n",
    "print(converted_sentence)\n",
    "\n",
    "\n",
    "# Step 4: Synthesize the output\n",
    "outputs = model.synthesize(\n",
    "    # \"Odi, tide na 19 fu april.\",\n",
    "    converted_sentence,\n",
    "    config,\n",
    "    speaker_wav=\"./xtts/nederlands.wav\",  # Replace with the correct path\n",
    "    # speaker_wav=\"./xtts/fr_sample.wav\",  # Replace with the correct path\n",
    "    gpt_cond_len=3,\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "# outputs = model.inference(\n",
    "#     \"It took me quite a long time to develop a voice...\",\n",
    "#     language=\"en\",\n",
    "#     speaker_wav=\"./xtts/en_sample.wav\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Step 5: Save the synthesized speech to a wav file\n",
    "output_wav = outputs['wav']\n",
    "\n",
    "# Play the sound\n",
    "sd.play(output_wav, config.audio.sample_rate)\n",
    "sd.wait()  # Wait until playback finishes\n",
    "\n",
    "sf.write('./output/output.wav', output_wav, config.audio.sample_rate)\n",
    "\n",
    "print(\"Speech synthesis complete and saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
