{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbe5bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config OK\n",
      "init OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\bin\\Python309\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model OK\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "import soundfile as sf\n",
    "\n",
    "# Load model configuration\n",
    "config = XttsConfig()\n",
    "config.load_json('./xtts/config.json')\n",
    "\n",
    "config.epochs = 1\n",
    "\n",
    "print('config OK')\n",
    "\n",
    "# Step 2: Initialize the model\n",
    "model = Xtts.init_from_config(config)\n",
    "\n",
    "print('init OK')\n",
    "\n",
    "# Step 3: Load the pre-trained weights\n",
    "model.load_checkpoint(config, checkpoint_dir=\"D:/LanguageModels/xtts/\", eval=True)\n",
    "\n",
    "print('model OK')\n",
    "\n",
    "# Optional: If you have CUDA installed and want to use GPU, uncomment the line below\n",
    "# model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab73f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dataset <class 'list'>\n",
      "type of dataset item <class 'dict'>\n",
      " dataset item {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number1.wav', 'text': '1', 'spoken_text': 'een', 'speaker_id': 'speaker1', 'duration': 2.0}\n",
      " | > Found 10 files in D:\\LanguageModels\\audiodata\n",
      "type of dataset <class 'list'>\n",
      "type of dataset item <class 'dict'>\n",
      " dataset item {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number1.wav', 'text': '1', 'spoken_text': 'een', 'speaker_id': 'speaker1', 'duration': 2.0}\n",
      "train_samples [{'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number1.wav', 'text': '1', 'spoken_text': 'een', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number1'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number2.wav', 'text': '2', 'spoken_text': 'twee', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number2'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number3.wav', 'text': '3', 'spoken_text': 'drie', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number3'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number4.wav', 'text': '4', 'spoken_text': 'vier', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number4'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number5.wav', 'text': '5', 'spoken_text': 'vijf', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number5'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number6.wav', 'text': '6', 'spoken_text': 'zes', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number6'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number7.wav', 'text': '7', 'spoken_text': 'zeven', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number7'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number8.wav', 'text': '8', 'spoken_text': 'acht', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number8'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number9.wav', 'text': '9', 'spoken_text': 'negen', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number9'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number10.wav', 'text': '10', 'spoken_text': 'tien', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number10'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "\n",
    "# from TTS.tts.configs import DatasetConfig\n",
    "\n",
    "\n",
    "\n",
    "def formatter(root_path='', meta_file_train='', ignored_speakers=None):\n",
    "    # Load JSON dataset\n",
    "    with open(\"D:/LanguageModels/audiodata/dutch_numbers_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    print('type of dataset' , type(dataset))    \n",
    "    print('type of dataset item' , type(dataset[0]))    \n",
    "    print(' dataset item' , dataset[0])  \n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset_config = BaseDatasetConfig (\n",
    "    dataset_name = \"tts_dataset_getallen\",\n",
    "    path = \"D:/LanguageModels/audiodata\",\n",
    "    # root_path = \"D:/LanguageModels/audiodata\",\n",
    "    formatter = formatter,\n",
    "    meta_file_train = \"D:/LanguageModels/audiodata/dutch_numbers_dataset.json\",\n",
    "    meta_file_val = \"D:/LanguageModels/audiodata/dutch_numbers_dataset.json\",\n",
    "    ignored_speakers = [] ,  # Define an empty list as a placeholder\n",
    "    language = \"Dutch\",  # Define language if missing\n",
    "    meta_file_attn_mask = None ,  # Define an empty list as a placeholder\n",
    "\n",
    ")\n",
    "\n",
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True, formatter=formatter)\n",
    "\n",
    "print('train_samples' , train_samples)\n",
    "\n",
    "\n",
    "# Function to load audio and preprocess dataset\n",
    "def preprocess(example):\n",
    "    # Load waveform and sample rate from file\n",
    "    waveform, sample_rate = torchaudio.load(example[\"audio_file\"])\n",
    "    \n",
    "    return {\n",
    "        \"speech_input\": waveform,  # Tensor representation of audio\n",
    "        # \"sample_rate\": sample_rate,  # Keep track of sample rate\n",
    "        # \"text\": example[\"text\"],  # Raw number text\n",
    "        \"text_output\": example[\"spoken_text\"]  # Human pronunciation\n",
    "    }\n",
    "\n",
    "    # return {\n",
    "    #     \"audio\": waveform,  # Tensor representation of audio\n",
    "    #     \"sample_rate\": sample_rate,  # Keep track of sample rate\n",
    "    #     \"text\": example[\"text\"],  # Raw number text\n",
    "    #     \"spoken_text\": example[\"spoken_text\"]  # Human pronunciation\n",
    "    # }\n",
    "\n",
    "# # Apply preprocessing to all examples\n",
    "# processed_dataset = [preprocess(example) for example in dataset]\n",
    "\n",
    "# # Example: Check first entry\n",
    "# print(processed_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62225299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BaseTTSConfig', 'List', 'XttsArgs', 'XttsAudioConfig', 'XttsConfig', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'dataclass', 'field']\n",
      "trainerArgs ['_MutableMapping__marker', '__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_initialized', '_is_initialized', '_keytransform', '_validate_contracts', 'best_path', 'check_values', 'clear', 'continue_path', 'copy', 'deserialize', 'deserialize_immutable', 'from_dict', 'get', 'gpu', 'grad_accum_steps', 'group_id', 'has', 'init_argparse', 'init_from_argparse', 'items', 'keys', 'load_json', 'merge', 'new_from_dict', 'overfit_batch', 'parse_args', 'parse_known_args', 'pop', 'popitem', 'pprint', 'rank', 'restore_path', 'save_json', 'serialize', 'setdefault', 'skip_train_epoch', 'small_run', 'start_with_eval', 'to_dict', 'to_json', 'update', 'use_accelerate', 'use_ddp', 'validate', 'values']\n",
      "model attributes ['MODEL_TYPE', 'T_destination', '__abstractmethods__', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_get_test_aux_input', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_set_model_args', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'ap', 'apply', 'args', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'config', 'cpu', 'cuda', 'decoder_checkpoint', 'device', 'double', 'dump_patches', 'eval', 'eval_log', 'eval_step', 'extra_repr', 'float', 'format_batch', 'format_batch_on_device', 'forward', 'full_inference', 'get_aux_input', 'get_aux_input_from_test_sentences', 'get_buffer', 'get_compatible_checkpoint_state_dict', 'get_conditioning_latents', 'get_data_loader', 'get_extra_state', 'get_gpt_cond_latents', 'get_parameter', 'get_sampler', 'get_speaker_embedding', 'get_submodule', 'gpt', 'gpt_batch_size', 'gpt_checkpoint', 'half', 'handle_chunks', 'hifigan_decoder', 'inference', 'inference_stream', 'init_for_training', 'init_from_config', 'init_models', 'init_multispeaker', 'ipu', 'language_manager', 'load_checkpoint', 'load_state_dict', 'mel_stats', 'mel_stats_path', 'models_dir', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'on_init_start', 'optimize', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'scaled_backward', 'set_extra_state', 'set_submodule', 'share_memory', 'speaker_manager', 'state_dict', 'synthesize', 'test_run', 'to', 'to_empty', 'tokenizer', 'train', 'train_log', 'train_step', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Num. of CPUs: 2\n",
      " | > Num. of Torch Threads: 2\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=D:/LanguageModels/logs\\run-April-12-2025_05+46AM-40b40a0\n",
      "\n",
      " > Model has 466874863 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1\u001b[0m\n",
      " --> D:/LanguageModels/logs\\run-April-12-2025_05+46AM-40b40a0\n",
      "\n",
      "\u001b[1m > TRAINING (2025-04-12 05:46:45) \u001b[0m\n",
      " ! Run is removed from D:/LanguageModels/logs\\run-April-12-2025_05+46AM-40b40a0\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1840, in fit\n",
      "    self._fit()\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1792, in _fit\n",
      "    self.train_epoch()\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1511, in train_epoch\n",
      "    outputs, _ = self.train_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1363, in train_step\n",
      "    outputs, loss_dict_new, step_time = self.optimize(\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1228, in optimize\n",
      "    outputs, loss_dict = self._compute_loss(\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1159, in _compute_loss\n",
      "    outputs, loss_dict = self._model_train_step(batch, model, criterion)\n",
      "  File \"c:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py\", line 1118, in _model_train_step\n",
      "    return model.train_step(*input_args)\n",
      "  File \"C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_7964\\1759075850.py\", line 128, in train_step\n",
      "    output = self.model.train_step(batch, criterion)\n",
      "TypeError: train_step() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training assets {}\n",
      "training samples [{'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number1.wav', 'text': '1', 'spoken_text': 'een', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number1'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number2.wav', 'text': '2', 'spoken_text': 'twee', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number2'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number3.wav', 'text': '3', 'spoken_text': 'drie', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number3'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number4.wav', 'text': '4', 'spoken_text': 'vier', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number4'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number5.wav', 'text': '5', 'spoken_text': 'vijf', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number5'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number6.wav', 'text': '6', 'spoken_text': 'zes', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number6'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number7.wav', 'text': '7', 'spoken_text': 'zeven', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number7'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number8.wav', 'text': '8', 'spoken_text': 'acht', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number8'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number9.wav', 'text': '9', 'spoken_text': 'negen', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number9'}, {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number10.wav', 'text': '10', 'spoken_text': 'tien', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number10'}]\n",
      "CustomDataset sample {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number7.wav', 'text': '7', 'spoken_text': 'zeven', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number7'}\n",
      "CustomDataset sample {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number6.wav', 'text': '6', 'spoken_text': 'zes', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number6'}\n",
      "CustomDataset sample {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number9.wav', 'text': '9', 'spoken_text': 'negen', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number9'}\n",
      "CustomDataset sample {'root_path': 'D:/LanguageModels/audiodata', 'audio_file': 'D:/LanguageModels/audiodata/number8.wav', 'text': '8', 'spoken_text': 'acht', 'speaker_id': 'speaker1', 'duration': 2.0, 'language': 'Dutch', 'audio_unique_name': 'tts_dataset_getallen#number8'}\n",
      "train_step batch {'root_path': ['D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata'], 'audio_file': ['D:/LanguageModels/audiodata/number7.wav', 'D:/LanguageModels/audiodata/number6.wav', 'D:/LanguageModels/audiodata/number9.wav', 'D:/LanguageModels/audiodata/number8.wav'], 'text': ['7', '6', '9', '8'], 'spoken_text': ['zeven', 'zes', 'negen', 'acht'], 'speaker_id': ['speaker1', 'speaker1', 'speaker1', 'speaker1'], 'duration': tensor([2., 2., 2., 2.], dtype=torch.float64), 'language': ['Dutch', 'Dutch', 'Dutch', 'Dutch'], 'audio_unique_name': ['tts_dataset_getallen#number7', 'tts_dataset_getallen#number6', 'tts_dataset_getallen#number9', 'tts_dataset_getallen#number8']}\n",
      "batch {'root_path': ['D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata'], 'audio_file': ['D:/LanguageModels/audiodata/number7.wav', 'D:/LanguageModels/audiodata/number6.wav', 'D:/LanguageModels/audiodata/number9.wav', 'D:/LanguageModels/audiodata/number8.wav'], 'text': ['7', '6', '9', '8'], 'spoken_text': ['zeven', 'zes', 'negen', 'acht'], 'speaker_id': ['speaker1', 'speaker1', 'speaker1', 'speaker1'], 'duration': tensor([2., 2., 2., 2.], dtype=torch.float64), 'language': ['Dutch', 'Dutch', 'Dutch', 'Dutch'], 'audio_unique_name': ['tts_dataset_getallen#number7', 'tts_dataset_getallen#number6', 'tts_dataset_getallen#number9', 'tts_dataset_getallen#number8']}\n",
      "batch on device {'root_path': ['D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata', 'D:/LanguageModels/audiodata'], 'audio_file': ['D:/LanguageModels/audiodata/number7.wav', 'D:/LanguageModels/audiodata/number6.wav', 'D:/LanguageModels/audiodata/number9.wav', 'D:/LanguageModels/audiodata/number8.wav'], 'text': ['7', '6', '9', '8'], 'spoken_text': ['zeven', 'zes', 'negen', 'acht'], 'speaker_id': ['speaker1', 'speaker1', 'speaker1', 'speaker1'], 'duration': tensor([2., 2., 2., 2.], dtype=torch.float64), 'language': ['Dutch', 'Dutch', 'Dutch', 'Dutch'], 'audio_unique_name': ['tts_dataset_getallen#number7', 'tts_dataset_getallen#number6', 'tts_dataset_getallen#number9', 'tts_dataset_getallen#number8'], 'audio_features': [array([[-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       ...,\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.]], dtype=float32), array([[-80.     , -80.     , -80.     , ..., -80.     , -79.75235,\n",
      "        -80.     ],\n",
      "       [-80.     , -80.     , -80.     , ..., -80.     , -80.     ,\n",
      "        -80.     ],\n",
      "       [-80.     , -80.     , -80.     , ..., -80.     , -80.     ,\n",
      "        -80.     ],\n",
      "       ...,\n",
      "       [-80.     , -80.     , -80.     , ..., -80.     , -80.     ,\n",
      "        -80.     ],\n",
      "       [-80.     , -80.     , -80.     , ..., -80.     , -80.     ,\n",
      "        -80.     ],\n",
      "       [-80.     , -80.     , -80.     , ..., -80.     , -80.     ,\n",
      "        -80.     ]], dtype=float32), array([[-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       ...,\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.]], dtype=float32), array([[-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       ...,\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.],\n",
      "       [-80., -80., -80., ..., -80., -80., -80.]], dtype=float32)]}\n",
      "XTTS expected arguments  ('self',)\n",
      "1\n",
      "XTTS functions ['MODEL_TYPE', 'T_destination', '__abstractmethods__', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_get_test_aux_input', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_set_model_args', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'ap', 'apply', 'args', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'config', 'cpu', 'cuda', 'decoder_checkpoint', 'device', 'double', 'dump_patches', 'eval', 'eval_log', 'eval_step', 'extra_repr', 'float', 'format_batch', 'format_batch_on_device', 'forward', 'full_inference', 'get_aux_input', 'get_aux_input_from_test_sentences', 'get_buffer', 'get_compatible_checkpoint_state_dict', 'get_conditioning_latents', 'get_data_loader', 'get_extra_state', 'get_gpt_cond_latents', 'get_parameter', 'get_sampler', 'get_speaker_embedding', 'get_submodule', 'gpt', 'gpt_batch_size', 'gpt_checkpoint', 'half', 'handle_chunks', 'hifigan_decoder', 'inference', 'inference_stream', 'init_for_training', 'init_from_config', 'init_models', 'init_multispeaker', 'ipu', 'language_manager', 'load_checkpoint', 'load_state_dict', 'mel_stats', 'mel_stats_path', 'models_dir', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'on_init_start', 'optimize', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'scaled_backward', 'set_extra_state', 'set_submodule', 'share_memory', 'speaker_manager', 'state_dict', 'synthesize', 'test_run', 'to', 'to_empty', 'tokenizer', 'train', 'train_log', 'train_step', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1840\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1840\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1792\u001b[0m, in \u001b[0;36mTrainer._fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_train_epoch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_with_eval:\n\u001b[1;32m-> 1792\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_eval:\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1511\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m-> 1511\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_start_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1363\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[1;34m(self, batch, batch_n_steps, step, loader_start_time)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;66;03m# auto training with a single optimizer\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m     outputs, loss_dict_new, step_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_optimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m     loss_dict\u001b[38;5;241m.\u001b[39mupdate(loss_dict_new)\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1228\u001b[0m, in \u001b[0;36mTrainer.optimize\u001b[1;34m(self, batch, model, optimizer, scaler, criterion, scheduler, config, optimizer_idx, step_optimizer, num_optimizers)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# forward pass and loss computation\u001b[39;00m\n\u001b[1;32m-> 1228\u001b[0m outputs, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# skip the rest if not outputs from the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1159\u001b[0m, in \u001b[0;36mTrainer._compute_loss\u001b[1;34m(self, batch, model, criterion, config, optimizer_idx)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1159\u001b[0m         outputs, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, loss_dict\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1118\u001b[0m, in \u001b[0;36mTrainer._model_train_step\u001b[1;34m(batch, model, criterion, optimizer_idx)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mtrain_step(\u001b[38;5;241m*\u001b[39minput_args)\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 128\u001b[0m, in \u001b[0;36mXTTSWrapper.train_step\u001b[1;34m(self, batch, criterion)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# output = self.model(texts, audio_features)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# output = self.model(texts, speaker_embeddings, audio_features)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Define loss function\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: train_step() takes 1 positional argument but 3 were given",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 192\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Start fine-tuning\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\bin\\Python309\\lib\\site-packages\\trainer\\trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1868\u001b[0m traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m-> 1869\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:1437\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:1328\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1325\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:1175\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1173\u001b[0m ):\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1175\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py:1162\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         FIs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1157\u001b[0m             FrameInfo(\n\u001b[0;32m   1158\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw frame\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename, lineno, frame, code, context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[0;32m   1159\u001b[0m             )\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FIs\n\u001b[1;32m-> 1162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n\u001b[0;32m   1163\u001b[0m res \u001b[38;5;241m=\u001b[39m [FrameInfo\u001b[38;5;241m.\u001b[39m_from_stack_data_FrameInfo(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstack_data\u001b[39m(\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     99\u001b[0m         current \u001b[38;5;241m=\u001b[39m current\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py:177\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    176\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import TTS.tts.configs\n",
    "print(dir(TTS.tts.configs.xtts_config))\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "\n",
    "from trainer import TrainerArgs\n",
    "\n",
    "from trainer import TrainerConfig\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "# import importlib\n",
    "# import ultratb\n",
    "\n",
    "# # Reload the module after making changes\n",
    "# importlib.reload(ultratb)\n",
    "\n",
    "\n",
    "config.output_path = 'D:/LanguageModels/logs'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print('CustomDataset sample' , self.samples[idx])\n",
    "        return self.samples[idx]\n",
    "    \n",
    "\n",
    "class XTTSWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model_name=\"coqui/XTTS-v2\", train_samples=None, batch_size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load the pre-trained XTTS model\n",
    "        self.model = model\n",
    "        \n",
    "        self.train_samples = train_samples\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define criterion (loss function)\n",
    "        self.criterion = nn.CrossEntropyLoss()  # Modify based on task\n",
    "\n",
    "    def get_criterion(self):\n",
    "        \"\"\"Provide the expected method\"\"\"\n",
    "        return self.criterion\n",
    "    \n",
    "    def get_data_loader(self, config, assets, is_eval, samples, verbose, num_gpus):\n",
    "        # wrap the model's data loader\n",
    "        return self.model.get_data_loader(\n",
    "                    config=config, assets=assets, is_eval=is_eval, samples=samples, verbose=verbose, num_gpus=num_gpus\n",
    "                )\n",
    "    \n",
    "    def get_train_data_loader(self, config, training_assets, samples, verbose, num_gpus):\n",
    "        \"\"\"Return DataLoader for training samples.\"\"\"\n",
    "        dataset = CustomDataset(self.train_samples)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    def extract_mel_spectrogram(self, audio_file):\n",
    "        \"\"\"Convert audio file into Mel spectrogram for XTTS.\"\"\"\n",
    "        y, sr = librosa.load(audio_file, sr=24000)  # Load waveform (XTTS uses 24kHz)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # Convert to dB\n",
    "\n",
    "        return mel_spec_db  # Return processed Mel spectrogram    \n",
    " \n",
    "    def format_batch(self, batch):\n",
    "            \"\"\"Format batch for XTTS training.\"\"\"\n",
    "            print('batch' , batch)\n",
    "\n",
    "            \"\"\"Convert audio files to Mel spectrograms and format batch.\"\"\"\n",
    "            audio_files = batch[\"audio_file\"]\n",
    "            audio_features = []\n",
    "            \n",
    "            for audio_file in audio_files:\n",
    "                audio_feature = self.extract_mel_spectrogram(audio_file)  # Convert audio\n",
    "                audio_features.append(audio_feature)\n",
    "\n",
    "            batch['audio_features'] = audio_features\n",
    "\n",
    "            return batch\n",
    "\n",
    "            return batch\n",
    "            # texts = [sample[\"text\"] for sample in batch]\n",
    "            # audio_files = [sample[\"audio_file\"] for sample in batch]\n",
    "            # speaker_ids = [sample[\"speaker_id\"] for sample in batch]\n",
    "\n",
    "            # return {\n",
    "            #     \"texts\": texts,\n",
    "            #     \"audio_files\": audio_files,\n",
    "            #     \"speaker_ids\": speaker_ids\n",
    "            # }\n",
    "\n",
    "    def format_batch_on_device(self, batch):\n",
    "            \"\"\"Format batch for XTTS training.\"\"\"\n",
    "            print('batch on device' , batch)\n",
    "\n",
    "            return batch\n",
    "\n",
    "\n",
    "    def forward(self, input_text, speaker_embeddings, audio_features):\n",
    "        \"\"\"Run XTTS forward pass\"\"\"\n",
    "        return self.model(input_text, speaker_embeddings, audio_features)\n",
    "\n",
    "    def train_step(self, batch, criterion):\n",
    "            \"\"\"Perform a single training step.\"\"\"\n",
    "            texts = batch[\"text\"]\n",
    "            # speaker_embeddings = batch[\"speaker_embeddings\"]\n",
    "            audio_features = batch[\"audio_features\"]\n",
    "\n",
    "            print('XTTS expected arguments ' , self.model.forward.__code__.co_varnames)  # Lists expected arguments\n",
    "            print(self.model.forward.__code__.co_argcount)  # Shows argument count\n",
    "\n",
    "            print('XTTS functions' , dir(self.model))\n",
    "\n",
    "            # Forward pass\n",
    "            output = self.model.train_step(batch, criterion)\n",
    "            # output = self.model(texts, audio_features)\n",
    "            # output = self.model(texts, speaker_embeddings, audio_features)\n",
    "\n",
    "            # Define loss function\n",
    "            loss = criterion(output, audio_features)  # Modify based on XTTS loss requirements\n",
    "\n",
    "            return loss\n",
    "\n",
    "\n",
    "# Initialize the wrapped model\n",
    "wrapped_model = XTTSWrapper(train_samples=train_samples)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "# train_dataset, eval_dataset = load_tts_samples(\"dataset/\", eval_split=True)\n",
    "trainerArgs = TrainerArgs()\n",
    "\n",
    "print('trainerArgs' , dir(trainerArgs))\n",
    "\n",
    "trainerArgs.log_to_file = False  # Prevents logging to disk\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])\n",
    "\n",
    "\n",
    "# config = XttsConfig() \n",
    "\n",
    "# Define fine-tuning configuration\n",
    "trainerConfig = TrainerConfig(\n",
    "    epochs = 3,  # Reduce epochs for fine-tuning\n",
    "    batch_size = 4,\n",
    "    save_step = 10000,\n",
    "    output_path = \"D:/LanguageModels/xtts-finetuned\"\n",
    ")\n",
    "\n",
    "\n",
    "print('model attributes' , dir(model))\n",
    "\n",
    "# Initialize trainer with pre-trained model\n",
    "trainer = Trainer(\n",
    "    model = wrapped_model,\n",
    "    args = trainerArgs,\n",
    "    config = config,\n",
    "    output_path = \"D:/LanguageModels/xtts-finetuned\",\n",
    "    train_samples = train_samples,\n",
    "    eval_samples = eval_samples\n",
    ")\n",
    "\n",
    "import logging\n",
    "\n",
    "class NoLoggingHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        pass  # Prevent logs from being written\n",
    "\n",
    "logging.getLogger().addHandler(NoLoggingHandler())\n",
    "\n",
    "\n",
    "trainer.criterion = CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"D:/LanguageModels/xtts-getallen\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
